{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open(\"/Users/divyamsharma/Desktop/TrumpSpeechTrain.txt\",\"rb\")\n",
    "Train_Data=f.read()\n",
    "Train_Data=str(Train_Data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading Training Data From File 1 and converting bytes to str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1=open(\"/Users/divyamsharma/Desktop/TrumpSpeechTest.txt\",\"rb\")\n",
    "Test_Data=f1.read()\n",
    "Test_Data=str(Test_Data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading Testing Data From File 2 and converting bytes to str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_Sentences=Train_Data.split('.')\n",
    "Test_Sentences=Test_Data.split('.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting Str type files into a list of sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_Sentence_Lengths=[]\n",
    "for i in Train_Sentences:\n",
    "    Train_Sentence_Lengths.append(len(i.split()))\n",
    "Test_Sentence_Lengths=[]\n",
    "for i in Test_Sentences:\n",
    "    Test_Sentence_Lengths.append(len(i.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making Lists of lengths of Training and Testing Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TuneData(Sentence_Lengths):\n",
    "    X=[]\n",
    "    Y=[]\n",
    "    for i in range(0,len(Sentence_Lengths)-5,1):\n",
    "        X.append([Sentence_Lengths[i],Sentence_Lengths[i+1],Sentence_Lengths[i+2],Sentence_Lengths[i+3],Sentence_Lengths[i+4]])\n",
    "        if(Sentence_Lengths[i+5]>10):\n",
    "            Y.append(1)\n",
    "        else:\n",
    "            Y.append(0)\n",
    "            \n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Function manipulates the input data in such a way that the returned X is a list of 5 consecutive sentences and Y is length of the 6th sentences. So, I am using the length of 6th sentence as a target for training my model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,Y_train=TuneData(Train_Sentence_Lengths)\n",
    "X_test,Y_test=TuneData(Test_Sentence_Lengths)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting my training and testing data to tune."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        28\n",
      "          1       0.64      0.98      0.77        50\n",
      "\n",
      "avg / total       0.41      0.63      0.49        78\n",
      "\n",
      "[[ 0 28]\n",
      " [ 1 49]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf = GaussianNB()\n",
    "clf.fit(X_train, Y_train)\n",
    "Y_pred = clf.predict(X_test)\n",
    "print(classification_report(Y_test,Y_pred))\n",
    "print(confusion_matrix(Y_test,Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.33      0.21      0.26        28\n",
      "          1       0.63      0.76      0.69        50\n",
      "\n",
      "avg / total       0.53      0.56      0.54        78\n",
      "\n",
      "[[ 6 22]\n",
      " [12 38]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, Y_train)\n",
    "Y_pred = clf.predict(X_test)\n",
    "print(classification_report(Y_test,Y_pred))\n",
    "print(confusion_matrix(Y_test,Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.43      0.26      0.32       113\n",
      "          1       0.63      0.79      0.70       185\n",
      "\n",
      "avg / total       0.56      0.59      0.56       298\n",
      "\n",
      "[[ 29  84]\n",
      " [ 39 146]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, Y_train)\n",
    "Y_pred = clf.predict(X_train)\n",
    "print(classification_report(Y_train,Y_pred))\n",
    "print(confusion_matrix(Y_train,Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.43      0.05      0.09       113\n",
      "          1       0.62      0.96      0.75       185\n",
      "\n",
      "avg / total       0.55      0.61      0.50       298\n",
      "\n",
      "[[  6 107]\n",
      " [  8 177]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf = GaussianNB()\n",
    "clf.fit(X_train, Y_train)\n",
    "Y_pred = clf.predict(X_train)\n",
    "print(classification_report(Y_train,Y_pred))\n",
    "print(confusion_matrix(Y_train,Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.savetxt(\"SentencePrediction.csv\",Y_pred,fmt=\"%.5f\")\n",
    "np.savetxt(\"SentenceTrue.csv\",Y_test,fmt=\"%.5f\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
